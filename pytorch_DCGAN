{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pytorch_DCGAN","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNDdIwawKfi7UGncpM4LYXo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"LPsMWMRt7Z0D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607060086745,"user_tz":-540,"elapsed":25449,"user":{"displayName":"임창민","photoUrl":"","userId":"01760191182637642533"}},"outputId":"de3466b4-9ea8-4e7f-8ffd-1178ba02890e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h_d9Ny4n77qo"},"source":["import os\n","import numpy as np\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BlM2J7ftOUAd"},"source":["import matplotlib.pyplot as plt\n","import torch\n","from torch import nn,optim\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","from torchvision.utils import save_image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gTy_RehL83v9"},"source":["#Image Preprocessing\n","batch_size = 32\n","batchSize = 64\n","imageSize = 64\n","\n","transform = transforms.Compose([transforms.Resize(64), transforms.CenterCrop(64),\n","                                transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))])\n","train_data = datasets.ImageFolder('/content/drive/My Drive/AI/input/data/train', transform = transform)\n","dataloader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n","imgs, label = next(iter(dataloader))\n","imgs = imgs.numpy().transpose(0, 2, 3, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kt4uHoJcOK2b"},"source":["batch_size = 32\n","image_size = 64\n","\n","random_transforms = [transforms.ColorJitter(), transforms.RandomRotation(degrees=20)]\n","transforms = transforms.Compose([transforms.Resize(64), transforms.CenterCrop(64),\n","                                 transforms.RandomHorizontalFlip(p=0.5),\n","                                 transforms.ToTensor(),\n","                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","train_data = datasets.ImageFolder('/content/drive/My Drive/AI/input/data/train', transform=transform)\n","train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n","imgs, label = next(iter(train_loader))\n","imgs = imgs.numpy().transpose(0, 2, 3, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pJ2SKQiHPw1I"},"source":["for i in range(20):\n","  print(label[i])\n","  plt.imshow(imgs[i])\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sDXo-ywwP4m_"},"source":["#weight\n","def weight_init(m):\n","  classname = m.__class__.__name__\n","  if classname.find('Conv') != -1:\n","    m.weight.data.normal_(0.0, 0.02)\n","  elif classname.find('BatchNorm') != -1:\n","    m.weight.data.normal_(1.0, 0.02)\n","    m.bias.data.fill_(0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PsZEkiEcQcA7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606886498303,"user_tz":-540,"elapsed":758,"user":{"displayName":"임창민","photoUrl":"","userId":"01760191182637642533"}},"outputId":"465fb806-9ac8-4240-b9be-29c0b447c49c"},"source":["#Generator\n","class G(nn.Module):\n","  def __init__(self):\n","    super(G, self).__init__()\n","    self.main = nn.Sequential(nn.ConvTranspose2d(100, 512, 4, stride=1, padding=0, bias=False),\n","                              nn.BatchNorm2d(512), nn.ReLU(True),\n","                              nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1, bias=False),\n","                              nn.BatchNorm2d(256),\n","                              nn.ReLU(True),\n","                              nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1, bias=False),\n","                              nn.BatchNorm2d(128),\n","                              nn.ReLU(True),\n","                              nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1, bias=False),\n","                              nn.BatchNorm2d(64),\n","                              nn.ReLU(True),\n","                              nn.ConvTranspose2d(64, 3, 4, stride=2, padding=1, bias=False),\n","                              nn.Tanh())\n","    \n","  def forward(self, input):\n","    output = self.main(input)\n","    return output\n","  \n","netG = G()\n","netG.apply(weight_init)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["G(\n","  (main): Sequential(\n","    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n","    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace=True)\n","    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (8): ReLU(inplace=True)\n","    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (11): ReLU(inplace=True)\n","    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (13): Tanh()\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"5YxOWepnRgJa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606886507134,"user_tz":-540,"elapsed":590,"user":{"displayName":"임창민","photoUrl":"","userId":"01760191182637642533"}},"outputId":"b232edab-1262-4df7-9cb6-7eda05110575"},"source":["#Discriminator(구분자)\n","class D(nn.Module):\n","  #네트워크 구조\n","  def __init__(self):\n","    super(D, self).__init__()\n","    self.main = nn.Sequential(\n","        nn.Conv2d(3, 64, 4, stride=2, padding=1, bias=False),\n","        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n","        nn.Conv2d(64,128,4,stride=2, padding=1, bias=False),\n","        nn.BatchNorm2d(128),\n","        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n","        nn.Conv2d(128, 256, 4, stride=2, padding=1, bias=False),\n","        nn.BatchNorm2d(256),\n","        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n","        nn.Conv2d(256, 512, 4, stride=2, padding=1, bias=False),\n","        nn.BatchNorm2d(512),\n","        nn.Conv2d(512, 1, 4, stride=1, padding=0, bias=False),\n","        nn.Sigmoid()\n","    )\n","  \n","  \n","  def forward(self, input):\n","    output = self.main(input)\n","    return output.view(-1)\n","\n","netD = D()\n","netD.apply(weight_init)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["D(\n","  (main): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (10): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n","    (11): Sigmoid()\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"GABvRWWLTSuw"},"source":["class Generator(nn.Module):\n","    def __init__(self, nz=128, channels=3):\n","        super(Generator, self).__init__()\n","        \n","        self.nz = nz\n","        self.channels = channels\n","        \n","        def convlayer(n_input, n_output, k_size=4, stride=2, padding=0):\n","            block = [\n","                nn.ConvTranspose2d(n_input, n_output, kernel_size=k_size, stride=stride, padding=padding, bias=False),\n","                nn.BatchNorm2d(n_output),\n","                nn.ReLU(inplace=True),\n","            ]\n","            return block\n","\n","        self.model = nn.Sequential(\n","            *convlayer(self.nz, 1024, 4, 1, 0), # Fully connected layer via convolution.\n","            *convlayer(1024, 512, 4, 2, 1),\n","            *convlayer(512, 256, 4, 2, 1),\n","            *convlayer(256, 128, 4, 2, 1),\n","            *convlayer(128, 64, 4, 2, 1),\n","            nn.ConvTranspose2d(64, self.channels, 3, 1, 1),\n","            nn.Tanh()\n","        )\n","\n","\n","    def forward(self, z):\n","        z = z.view(-1, self.nz, 1, 1)\n","        #print(z)\n","        z\n","        img = self.model(z)\n","        return img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WWH5lYmpVIdW"},"source":["class Discriminator(nn.Module):\n","    def __init__(self, channels=3):\n","        super(Discriminator, self).__init__()\n","        \n","        self.channels = channels\n","\n","        def convlayer(n_input, n_output, k_size=4, stride=2, padding=0, bn=False):\n","            block = [nn.Conv2d(n_input, n_output, kernel_size=k_size, stride=stride, padding=padding, bias=False)]\n","            if bn:\n","                block.append(nn.BatchNorm2d(n_output))\n","            block.append(nn.LeakyReLU(0.2, inplace=True))\n","            return block\n","\n","        self.model = nn.Sequential(\n","            *convlayer(self.channels, 32, 4, 2, 1),\n","            *convlayer(32, 64, 4, 2, 1),\n","            *convlayer(64, 128, 4, 2, 1, bn=True),\n","            *convlayer(128, 256, 4, 2, 1, bn=True),\n","            nn.Conv2d(256, 1, 4, 1, 0, bias=False),  # FC with Conv.\n","        )\n","\n","    def forward(self, imgs):\n","        logits = self.model(imgs)\n","        out = torch.sigmoid(logits)\n","    \n","        return out.view(-1, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7wncBL6XWcYZ"},"source":["#Training\n","EPOCH = 0\n","LR = 0.001\n","criterion = nn.BCELoss()\n","optimizerD = optim.Adam(netD.parameters(), lr=LR, betas=(0.5, 0.999))\n","optimizerG = optim.Adam(netG.parameters(), lr=LR, betas=(0.5, 0.999))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XQ_6iH2HLXKy"},"source":[""]},{"cell_type":"code","metadata":{"id":"gBknMlKNYy_0"},"source":["for epoch in range(EPOCH):\n","    for i, data in enumerate(dataloader, 0):\n","       #1st step : 판별자의 신경망 가중치 업데이트\n","        netD.zero_grad()\n","        \n","       #데이터 세트의 실제 이미지로 판별 자 훈련\n","        real,_ = data\n","        input = Variable(real)\n","        target = Variable(torch.ones(input.size()[0]))\n","        output = netD(input)\n","        errD_real = criterion(output, target)\n","        \n","       #생성기가 생성한 가짜 이미지로 판별자를 훈련\n","        noise = Variable(torch.randn(input.size()[0], 100, 1, 1))\n","        fake = netG(noise)\n","        target = Variable(torch.zeros(input.size()[0]))\n","        output = netD(fake.detach())\n","        errD_fake = criterion(output, target)\n","        \n","        #총 오류역 전파\n","        errD = errD_real + errD_fake\n","        errD.backward()\n","        optimizerD.step()\n","        \n","        #2nd step : 생성기의 신경망 가중치 업데이트\n","        netG.zero_grad()\n","        target = Variable(torch.ones(input.size()[0]))\n","        output = netD(fake)\n","        errG = criterion(output, target)\n","        errG.backward()\n","        optimizerG.step()\n","        \n","        #3rd step : 손실을 인쇄하고 100 단계마다 미니 배치의 실제 이미지와 생성된 이미지 저장\n","        if i % 100 == 0:\n","            vutils.save_image(real, '%s/real_samples.png' % \"./results\", normalize=True)\n","            fake = netG(noise)\n","            vutils.save_image(fake.data, '%s/fake_samples_epoch_%03d.png' % (\"./results\", epoch), normalize=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PwkEeYXmZDsQ"},"source":["batch_size = 32\n","LR_G = 0.001\n","LR_D = 0.0005\n","\n","beta1 = 0.5\n","epochs = 1000\n","\n","real_label = 0.9\n","fake_label = 0.1\n","nz = 128\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"54yg9XdoZeHP"},"source":["#모델 및 최적화 프로그램 초기화\n","netG = Generator(nz).to(device)\n","netD = Discriminator().to(device)\n","\n","criterion = nn.BCELoss()\n","\n","optimizerD = optim.Adam(netD.parameters(), lr=LR_D, betas=(beta1, 0.999))\n","optimizerG = optim.Adam(netG.parameters(), lr=LR_G, betas=(beta1, 0.999))\n","\n","fixed_noise = torch.randn(25, nz, 1, 1, device=device)\n","\n","G_losses = []\n","D_losses = []\n","epoch_time = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SqI20H_1Zfm7"},"source":["def plot_loss (G_losses, D_losses, epoch):\n","    plt.figure(figsize=(10,5))\n","    plt.title(\"Generator and Discriminator Loss - EPOCH \"+ str(epoch))\n","    plt.plot(G_losses,label=\"G\")\n","    plt.plot(D_losses,label=\"D\")\n","    plt.xlabel(\"iterations\")\n","    plt.ylabel(\"Loss\")\n","    plt.legend()\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OujwwKdZanTF"},"source":["def show_generated_img(n_images=5):\n","    sample = []\n","    for _ in range(n_images):\n","        noise = torch.randn(1, nz, 1, 1, device=device)\n","        gen_image = netG(noise).to(\"cpu\").clone().detach().squeeze(0)\n","        gen_image = gen_image.numpy().transpose(1, 2, 0)\n","        sample.append(gen_image)\n","    \n","    figure, axes = plt.subplots(1, len(sample), figsize = (64,64))\n","    for index, axis in enumerate(axes):\n","        axis.axis('off')\n","        image_array = sample[index]\n","        axis.imshow(image_array)\n","        \n","    plt.show()\n","    plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TEIX5PRhbB3G"},"source":["import time\n","from tqdm.notebook import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pPTRwVbiavxM"},"source":["for epoch in range(epochs):\n","    \n","    start = time.time()\n","    for ii, (real_images, train_labels) in tqdm(enumerate(train_loader), total=len(train_loader)):\n","\n","        # train with real\n","        netD.zero_grad()\n","        real_images = real_images.to(device)\n","        batch_size = real_images.size(0)\n","        labels = torch.full((batch_size, 1), real_label, device=device)\n","\n","        output = netD(real_images)\n","        errD_real = criterion(output, labels)\n","        errD_real.backward()\n","\n","        # train with fake\n","        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n","        fake = netG(noise)\n","        labels.fill_(fake_label)\n","        output = netD(fake.detach())\n","        errD_fake = criterion(output, labels)\n","        errD_fake.backward()\n","\n","        errD = errD_real + errD_fake\n","        optimizerD.step()\n","\n","        netG.zero_grad()\n","        labels.fill_(real_label)  # fake labels are real for generator cost\n","        output = netD(fake)\n","        errG = criterion(output, labels)\n","        errG.backward()\n","        optimizerG.step()\n","        \n","        # Save Losses for plotting later\n","        G_losses.append(errG.item())\n","        D_losses.append(errD.item())\n","    \n","    if epoch % 100 == 0:\n","        show_generated_img()\n","        plot_loss (G_losses, D_losses, epoch)\n","        G_losses = []\n","        D_losses = []\n","    \n","    epoch_time.append(time.time()- start)\n","    \n","#             valid_image = netG(fixed_noise)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kEoQj-CFaz4D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606470088513,"user_tz":-540,"elapsed":710,"user":{"displayName":"임창민","photoUrl":"","userId":"01760191182637642533"}},"outputId":"76494c67-e207-42f1-9416-bc1fda8426ef"},"source":["print (\">> average EPOCH duration = \", np.mean(epoch_time))"],"execution_count":null,"outputs":[{"output_type":"stream","text":[">> average EPOCH duration =  nan\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n","  out=out, **kwargs)\n","/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"lJL96fRoDc6X"},"source":[" if not os.path.exists('../output_images'):\n","    os.mkdir('../output_images')\n","    \n","im_batch_size = 50\n","n_images=10000\n","\n","for i_batch in tqdm(range(0, n_images, im_batch_size)):\n","    gen_z = torch.randn(im_batch_size, nz, 1, 1, device=device)\n","    gen_images = netG(gen_z)\n","    images = gen_images.to(\"cpu\").clone().detach()\n","    images = images.numpy().transpose(0, 2, 3, 1)\n","    for i_image in range(gen_images.size(0)):\n","        save_image(gen_images[i_image, :, :, :], os.path.join('../output_images', f'image_{i_batch+i_image:05d}.png'))"],"execution_count":null,"outputs":[]}]}